{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd7a40e5-bbde-443e-8017-bd7a747f59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce16ad0c-7f9a-42b9-9b91-c1b2104b5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Трансформация. Преобразование данных в другой тип (исходно как PIL импортирует).\n",
    "# Compose - трансформация, которая объединяет в себе другие трансформации. (массив трансформаций)\n",
    "\n",
    "trans = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((224, 224)), # если в датасете изображения разного размера\n",
    "    tv.transforms.ToTensor(),         # Превращение PIL в тензор\n",
    "    tv.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # тк хотим использовать модель vgg (а эти mean и std описаны на сайте pytorch)\n",
    "])\n",
    "\n",
    "dataset_path = \"animals10\"\n",
    "dataset_train = tv.datasets.ImageFolder(\n",
    "    root=dataset_path,\n",
    "    transform=trans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227fd14e-e64b-442c-a99e-8d1c06b7de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fcb7ea-599f-4b43-8176-abecd772dcc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# проверка что работает train_loader\n",
    "for sample in train_loader:\n",
    "    print(sample)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc12b24-00f9-4354-a9d4-8e2ddc0d5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c5bb9e-3caf-434f-8a02-f9b04f58f908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egoryakovlev/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /Users/egoryakovlev/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 548M/548M [01:18<00:00, 7.30MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = tv.models.vgg19(weights=tv.models.vgg.VGG19_Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb5b8957-623f-4a79-80d2-c8d3a21c29b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egoryakovlev/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/egoryakovlev/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:13<00:00, 7.62MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_resnet = tv.models.resnet50(weights=tv.models.ResNet50_Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4617511-a3d2-4f99-91ad-3d9d540f3099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143667240"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd98d67c-6205-4ee6-bb96-156af4c91244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20024384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(model.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "547012f0-a5be-4145-a1ea-96866bda6828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123642856"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b69f1550-0b0a-4ee2-8004-99b82f89fd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb51c37e-cb4a-4498-b0d6-3b1f552b3ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25557032"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "771fa138-b16e-4fb3-9b80-ca0888169be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пишем свой классификатор\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 100),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(100, 10)\n",
    ")\n",
    "\n",
    "# Применяем классификатор к модели\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fed3dd3b-c5ab-4adb-b57d-3a9765e2eb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2510920"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39de5bd6-a154-450d-8ae8-ebce7cd73243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переобучаем только классификатор\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "sheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "366ba484-a399-4ad9-9ba2-4ca6cd8e9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "fn_loss = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ca1cd90-5b2a-48ab-857c-4ae6f795a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label):\n",
    "    answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1)\n",
    "    return answer.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "329bf98a-71b1-49da-b8ec-70e1039e3b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egoryakovlev/opt/anaconda3/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "use_amp = True\n",
    "scaler = torch.cuda.amp.GradScaler() # только для GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8c5779d-7d13-426e-b363-92114b6cbcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1682c3d2-545c-429a-9569-324ce14a589d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Эти строки кода используются для настройки поведения библиотеки cuDNN при работе с GPU в PyTorch, и их выбор может существенно влиять на производительность и воспроизводимость вычислений.\n",
    "\n",
    "### 1. `torch.backends.cudnn.benchmark = True`\n",
    "Эта строка включает режим benchmark в cuDNN. Когда `benchmark` установлен в `True`, PyTorch запускает несколько испытательных прогонов, чтобы определить оптимальные параметры для конкретного слоя (например, размер блока для сверток). Это может значительно ускорить обучение и инференс, особенно если у вас стабильные входные размеры.\n",
    "\n",
    "**Преимущества:**\n",
    "- **Ускорение вычислений:** Оптимизирует производительность путем выбора наиболее быстрого алгоритма для текущей конфигурации.\n",
    "\n",
    "**Недостатки:**\n",
    "- **Время на старт:** На начальном этапе потребуется время для проведения тестов, что может увеличить время первого запуска.\n",
    "- **Подходит только для стабильных размеров входных данных:** Если размеры входных данных меняются, эта оптимизация может не сработать.\n",
    "\n",
    "### 2. `torch.backends.cudnn.deterministic = False`\n",
    "Эта строка отключает детерминированное поведение cuDNN. В случае, когда `deterministic` установлен в `False`, cuDNN может использовать не полностью детерминированные алгоритмы, которые могут приводить к различным результатам при каждом запуске.\n",
    "\n",
    "**Преимущества:**\n",
    "- **Ускорение вычислений:** Нехоть детерминированные алгоритмы могут быть быстрее и эффективнее по сравнению с их детерминированными аналогами.\n",
    "\n",
    "**Недостатки:**\n",
    "- **Невоспроизводимость:** Результаты могут немного различаться между запусками, что затрудняет отладку и воспроизводимость экспериментов.\n",
    "\n",
    "### Когда использовать эти настройки?\n",
    "- **Для производительности:** Используйте `torch.backends.cudnn.benchmark = True` и `torch.backends.cudnn.deterministic = False`, если вам важна максимальная производительность и стабильные размеры входных данных.\n",
    "- **Для воспроизводимости:** Установите `torch.backends.cudnn.deterministic = True` (и, возможно, `torch.backends.cudnn.benchmark = False`), если вам необходимо, чтобы результаты были воспроизводимы при каждом запуске.\n",
    "\n",
    "Эти настройки помогают балансировать между скоростью и воспроизводимостью, в зависимости от конкретных потребностей вашего проекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b579e8-6dff-41e5-9ac1-4308d5e3565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "loss_epochs_list = []\n",
    "acc_epochs_list = []\n",
    "for epoch in range(epochs):\n",
    "    loss_val = 0\n",
    "    acc_val = 0\n",
    "    for sample in (pbar := tqdm(train_loader)):\n",
    "        img, label = sample\n",
    "        label = F.one_hot(label, 10).float()\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(use_amp):\n",
    "            pred = model(img)\n",
    "            loss = loss_fn(pred, label)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        acc_current = accuracy(pred.cpu().float(), label.cpu().float())\n",
    "        acc_val += acc_current\n",
    "\n",
    "        pbar.set_description(f'loss: {loss_item:.5f}\\taccuracy: {acc_current:.3f}')\n",
    "    scheduler.step()\n",
    "    loss_epochs_list += [loss_val/len(train_loader)]\n",
    "    acc_epochs_list += [acc_val/len(train_loader)]\n",
    "    print(loss_epochs_list[-1])\n",
    "    print(acc_epochs_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86702890-9111-4108-aca6-be5af8bb5b39",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Процесс обучения нейронной сети с использованием PyTorch.Описание шагов:\n",
    "\n",
    "1. **Параметры обучения**:\n",
    "   - `epochs = 10`: Количество эпох обучения, то есть полных проходов по всему набору данных.\n",
    "   - `loss_epochs_list = []`: Список для сохранения значений функции потерь после каждой эпохи.\n",
    "   - `acc_epochs_list = []`: Список для сохранения значений точности после каждой эпохи.\n",
    "\n",
    "2. **Цикл по эпохам**:\n",
    "   - `for epoch in range(epochs)`: Цикл по числу эпох.\n",
    "   - `loss_val = 0`: Переменная для накопления значения функции потерь за эпоху.\n",
    "   - `acc_val = 0`: Переменная для накопления значения точности за эпоху.\n",
    "\n",
    "3. **Цикл по батчам (пакетам) данных**:\n",
    "   - `for sample in (pbar := tqdm(train_loader))`: Итерация по батчам данных из загрузчика `train_loader` с использованием прогресс-бара `tqdm`.\n",
    "\n",
    "4. **Подготовка данных**:\n",
    "   - `img, label = sample`: Получение изображений и меток из текущего батча.\n",
    "   - `label = F.one_hot(label, 10).float()`: Преобразование меток в one-hot представление и преобразование к типу float.\n",
    "   - `img = img.to(device)`: Перенос изображений на устройство (например, GPU).\n",
    "   - `label = label.to(device)`: Перенос меток на устройство.\n",
    "\n",
    "5. **Обнуление градиентов**:\n",
    "   - `optimizer.zero_grad()`: Обнуление градиентов перед обратным проходом.\n",
    "\n",
    "6. **Форвардный проход и вычисление функции потерь**:\n",
    "   - `with autocast(use_amp)`: Контекстный менеджер для автоматического приведения типов (если используется mixed precision).\n",
    "   - `pred = model(img)`: Прогон данных через модель для получения предсказаний.\n",
    "   - `loss = loss_fn(pred, label)`: Вычисление функции потерь.\n",
    "\n",
    "7. **Обратный проход и обновление весов**:\n",
    "   - `scaler.scale(loss).backward()`: Масштабирование и обратный проход для вычисления градиентов.\n",
    "   - `loss_item = loss.item()`: Получение значения функции потерь.\n",
    "   - `loss_val += loss_item`: Добавление значения функции потерь к общему значению за эпоху.\n",
    "   - `scaler.step(optimizer)`: Обновление весов модели.\n",
    "   - `scaler.update()`: Обновление скейлера.\n",
    "\n",
    "8. **Вычисление точности**:\n",
    "   - `acc_current = accuracy(pred.cpu().float(), label.cpu().float())`: Вычисление точности для текущего батча.\n",
    "   - `acc_val += acc_current`: Добавление значения точности к общему значению за эпоху.\n",
    "\n",
    "9. **Обновление прогресс-бара**:\n",
    "   - `pbar.set_description(f'loss: {loss_item:.5f}\\taccuracy: {acc_current:.3f}')`: Обновление описания прогресс-бара значениями функции потерь и точности.\n",
    "\n",
    "10. **Шаг планировщика обучения**:\n",
    "    - `scheduler.step()`: Обновление параметров планировщика обучения.\n",
    "\n",
    "11. **Сохранение значений функции потерь и точности за эпоху**:\n",
    "    - `loss_epochs_list += [loss_val/len(train_loader)]`: Добавление среднего значения функции потерь за эпоху в список.\n",
    "    - `acc_epochs_list += [acc_val/len(train_loader)]`: Добавление среднего значения точности за эпоху в список.\n",
    "    - `print(loss_epochs_list[-1])`: Печать последнего значения функции потерь.\n",
    "    - `print(acc_epochs_list[-1])`: Печать последнего значения точности.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9673c783-306f-453c-980d-a528c628f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a5e53-fb05-4c54-a727-0fcbaf1bc0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Accuracy\")\n",
    "plt.plot(acc_epochs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f95e545-bd71-4bcb-9c99-457945dd372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = sample[0][0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab8e991-a60e-4bf5-a859-c1e27669ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ans = model(img.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a97762-d7fd-4fb6-be2f-5738f25ebf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(ans.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e128d505-da95-4123-8df9-4ee3a87be0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
